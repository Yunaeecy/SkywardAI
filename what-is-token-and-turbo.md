# üêØ What is 'token' and 'turbo'?

In the context of LLM, tokens are the <mark style="color:purple;">**basic units of text or code**</mark> that an LLM AI uses to process and generate language. Tokens can be characters, words, subwords, or other segments of text or code, depending on the chosen tokenization method or scheme. Tokenization is the process of **splitting the input and output texts into smaller units** that can be processed by the LLM AI models. Tokens are <mark style="color:purple;">**assigned numerical values or identifiers**</mark> and are arranged in sequences or vectors, and are fed into or outputted from the model. The number of tokens parameter allows you to set a limit to how many tokens are generated. The natural limit to **the number of tokens** the model can produce varies **depending on the model size**, with smaller models going up to 1024 and larger models going up to 2048. It is generaally recommended to generate in short bursts instead of one long burst to avoid the model going off in a direction you are not expecting.

### What does tokenization have to do with the cost of running a model? <a href="#what-does-tokenization-have-to-do-with-the-cost-of-running-a-model" id="what-does-tokenization-have-to-do-with-the-cost-of-running-a-model"></a>

Tokenization affects the amount of data and the number of calculations that the model needs to process. The more tokens that the model ahs to deal with, the more memory and computational resources that the model consumes. Therefore, the cost of running an OpenAI or **Azure OpenAI** model depends on the tokenization method and the vocabulary size that the model uses, as well as the length and the complexity of the input and output texts. Based on the number of tokens used for interacting with a model and the different rates for different models, your costs can widely differ. For example, as of February 2023, the rate for using **Davinci** is $0.06 per 1,000 tokens, while the rate for using Ada is $0.0008 per 1,000 tokens. The rate also varies depending on the type of usage, such as playground, search, or engine. Therefore, tokenization is an important factor that influences the cost and the perforence of running an OpenAI or Azure OpenAI model.

## Azure OpenAI Service

It is **a cloud-based service** that provides REST API access to OpenAI's powerful language models, including the GPT-3, Codex, and Embeddings model seriers. The service also offers the new GPT-4 and ChatGPT(gpt-35-turbo) model series in preview. These models can be easily adapted to specific tasks, including content generation, summarization, semantic search, and natural language to code translation. Users can access the service through REST APIs, Python SDK, or the web-based interface in the Azure OpenAI Studio.

## Turbo

Turbo is a team used in the context of OpenAI's language models, specially <mark style="color:red;">**GPT-3.5 Turbo**</mark>, which is an improved version of GPT-3.5 and GPT-3 Davinci. The GPT-3.5 Turbo model is OpenAI's latest and most advanced language model, which powers the popupar ChatGPT. It can accept a series of messages as input, unlike the previous version that only allowed a single text prompt. This capability unlocks some interesting features, such as the ability to generate more complex and meaningful responses. The GPT-3.5 Turbo model is part of the GPT-3 family of models that can understand and generate natural language or code.
